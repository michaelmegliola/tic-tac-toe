{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q Learning\n",
    "\n",
    "Here is a maze, with the entrance marked __E__ (coordinates 0,0) and the exit marked __X__ (coordinates 3,3); the spaces containing 1's are blocked, while the spaces containing 0's are open:\n",
    "<pre>\n",
    "[E 0 0 1]\n",
    "[0 1 0 0]\n",
    "[0 0 1 0]\n",
    "[1 1 0 X]\n",
    "</pre>\n",
    "\n",
    "The goal is to traverse the maze by moving North, South, East,or West using a __Q Learning__ alogrithm.\n",
    "\n",
    "Note that there is one path through the maze:\n",
    "<pre>\n",
    "[E . . 1]\n",
    "[0 1 . .]\n",
    "[0 0 1 .]\n",
    "[1 1 0 X]\n",
    "</pre>\n",
    "\n",
    "Let's create a class for the maze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Maze():\n",
    "    \n",
    "    def __init__(self, random=False):\n",
    "        if random:\n",
    "            self.maze = np.random.randint(0,2,size=(4,4))\n",
    "            self.maze[0][0] = 0  # no obstacles allowed at starting point...\n",
    "            self.maze[3][3] = 0  # ...or at ending point.\n",
    "        else:\n",
    "            self.maze = np.array([[0,0,0,1],[0,1,0,0],[0,0,1,0],[1,1,0,0]])  # the initial maze is hardcoded\n",
    "          \n",
    "m = Maze()\n",
    "print('== ORIGINAL ==')\n",
    "print(m.maze)  \n",
    "m = Maze(random=True)\n",
    "print('== RANDOM ====')\n",
    "print(m.maze)\n",
    "print('note: the random maze may have no solution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the maze to act as an environment for machine learning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is what happens if you go out of bounds:\n",
      "[ 0 -1] -1 True\n",
      "(the coordinates are off the maze,\n",
      " the reward is negative,\n",
      " and the episode is done)\n",
      "\n",
      "...and here is the only safe path through the maze:\n",
      "(array([0, 1]), 0, False)\n",
      "(array([0, 2]), 0, False)\n",
      "(array([1, 2]), 0, False)\n",
      "(array([1, 3]), 0, False)\n",
      "(array([2, 3]), 0, False)\n",
      "(array([3, 3]), 1, True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Maze():\n",
    "    \n",
    "    N,S,E,W = 0,1,2,3\n",
    "    # offsets to move North, South, East, or West\n",
    "    offset = [(-1,0),(1,0),(0,1),(0,-1)]\n",
    "    \n",
    "    def __init__(self, random=False):   \n",
    "        self.reset(random)\n",
    "    \n",
    "    # moved code from __init__ to here, to allow re-use of Maze instance\n",
    "    def reset(self, random=False):\n",
    "        if random:\n",
    "            self.maze = np.random.randint(0,2,size=(4,4))\n",
    "            self.maze[0][0] = 0  # no obstacles allowed at starting point...\n",
    "            self.maze[3][3] = 0  # ...or at ending point.\n",
    "        else:\n",
    "            self.maze = np.array([[0,0,0,1],[0,1,0,0],[0,0,1,0],[1,1,0,0]])  # the initial maze is hardcoded\n",
    "        self.player = np.array([0,0])\n",
    "        self.path = np.zeros([4,4])\n",
    "        self.i = 1\n",
    "        self.path[0][0] = self.i  # initial position\n",
    "        return self.player\n",
    "    \n",
    "    # action should be one of: Maze.N, Maze.S, Maze.E, Maze.W\n",
    "    # returns reward, done\n",
    "    # rewards are: +1 = success, -1 = failure, 0 = no outcome\n",
    "    # done = True if a terminal state is reached, otherwise False\n",
    "    def step(self, action):\n",
    "        self.i += 1\n",
    "        self.player = np.add(self.player, Maze.offset[action])\n",
    "        if max(self.player) > 3 or min(self.player) < 0:        # out of bounds\n",
    "            return self.player, -1, True\n",
    "        else:\n",
    "            self.path[self.player[0]][self.player[1]] = self.i\n",
    "            if self.maze[self.player[0]][self.player[1]] != 0:  # moved onto a blocked space\n",
    "                return self.player, -1, True\n",
    "            elif np.array_equal(self.player, (3,3)):            # reached the exit\n",
    "                return self.player, 1, True\n",
    "            else:\n",
    "                return self.player, 0, False                    # no outcome (player is on an open space)\n",
    "    \n",
    "    # return a random action (equally distributed across the action space)\n",
    "    def sample(self):\n",
    "        return np.random.randint(4)      \n",
    "\n",
    "print('Here is what happens if you go out of bounds:')\n",
    "e = Maze()\n",
    "observation, reward, done = e.step(Maze.W)\n",
    "print(observation, reward, done)\n",
    "print('(the coordinates are off the maze,\\n the reward is negative,\\n and the episode is done)\\n')\n",
    "print('...and here is the only safe path through the maze:')\n",
    "e = Maze()\n",
    "print(e.step(Maze.E))\n",
    "print(e.step(Maze.E))\n",
    "print(e.step(Maze.S))\n",
    "print(e.step(Maze.E))\n",
    "print(e.step(Maze.S))\n",
    "print(e.step(Maze.S))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPlayer():\n",
    "    \n",
    "    EXPLORE = 0.01\n",
    "    \n",
    "    N,S,E,W = 0,1,2,3\n",
    "    \n",
    "    def __init__(self, explore=EXPLORE):\n",
    "        super().__init__()\n",
    "        self.q_table = np.zeros([4*4,4])\n",
    "        self.explore = explore\n",
    "        \n",
    "    def run(self, environment):\n",
    "        observation = environment.reset()\n",
    "        done = False\n",
    "        complete = 0\n",
    "        while not done:\n",
    "            state = observation[0] * 4 + observation[1]\n",
    "            action = np.argmax(self.q_table[state])\n",
    "            if action == 0 or np.random.random() < self.explore:\n",
    "                action = environment.sample()\n",
    "            observation, reward, done = environment.step(action)\n",
    "            if done:\n",
    "                self.q_table[state][action] = reward\n",
    "                return reward\n",
    "            else:\n",
    "                future_state = observation[0] * 4 + observation[1]\n",
    "                self.q_table[state][action] += reward + np.amax(self.q_table[future_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  0. 21. -1.]\n",
      " [-1. -1. 35.  0.]\n",
      " [-1. 35. -1.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0. -1. 21. -1.]\n",
      " [-1.  7.  0.  0.]\n",
      " [ 0. -1.  0. -1.]\n",
      " [-1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "q = QPlayer()\n",
    "e = Maze()\n",
    "complete = 0\n",
    "for n in range(100000):\n",
    "    complete += 1 if q.run(e) > 0 else 0\n",
    "    if np.sum(q.q_table) > 100:\n",
    "        print(q.q_table)\n",
    "        break\n",
    "print(complete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3. 0.]\n",
      " [0. 0. 4. 5.]\n",
      " [0. 0. 0. 6.]\n",
      " [0. 0. 0. 7.]]\n"
     ]
    }
   ],
   "source": [
    "print(e.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.run(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
